# AudioClassificationProject

## Task
Investigate the techniques behind audio classification and build a neural network model that performs a supervised classification. 
For this lab we choose to go for the subdomain of audio classification of the environment sounds. Thatâ€™s why we picked the dataset UrbanSound8K. It offers sound segments sliced to at 4 seconds maximum.
Implementation was done in Python using Keras library that abstracts on top of TensorFlow. Conda virtual environment was used to run jupyter-notebook that will help to visualize each step and what was achieved.


## Dataset
Urban8k dataset contains 8732 labeled sound excerpts, each of them is less than 4 seconds long. All sounds are from an urban environment and in total there are ten classes, labeled from 0 to 9:
0. air_conditioner  
1. car_horn  
2. children_playing  
3. dog_bark  
4. drilling  
5. engine_idling
6. gun_shot
7. jackhammer
8. siren
9. street_music

## Important: TODO once you sync the repo locally
Since the dataset is too large (8Gb), syncing it on Github would be unpractical. Please do the following to get the code to work as it is:
1. Download the UrbanDataset8K from [here](https://urbansounddataset.weebly.com/download-urbansound8k.html)
2. Unzip the content and delete everything except the folders named fold1 up to fold10.
3. Add all the fold[1-10] folder to a new folder with the name 'UrbanSound8K' inside the 'data' folder that is already there.
4. The final folder structure should look like:
![alt text](https://i.imgur.com/UrT6glx.png)

## Set up the environment and run jupyter notebook
1. Install Conda environment: ```conda create -n audio python=3.6 keras sklearn pandas numpy```
2. Activate the conda environment: ```source activate audio``` (in Windows: ```activate audio```)
3. Install Librosa with pip: ```pip install librosa```
4. cd inside the folder ```AudioClassificationProject``` from terminal
5. Run Jupyter: ```jupyter-notebook```
6. Have fun!
